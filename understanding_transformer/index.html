<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer 모델 심층 이해</title>
    <link rel="stylesheet" href="styles.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                displayMath: [['$$', '$$'], ['\\[', '\\]']],
                processEscapes: true,
                processEnvironments: true
            },
            options: {
                skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
            }
        };
        </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <header>
        <h1>Transformer 모델 심층 이해</h1>
    </header>
    <nav id="table-of-contents">
        <h2>목차</h2>
        <ul>
            <li><a href="#intro">1. 소개</a>
                <ul>
                    <li><a href="#background">1.1 배경</a></li>
                    <li><a href="#importance">1.2 중요성</a></li>
                </ul>
            </li>
            <li><a href="#architecture">2. Transformer 아키텍처</a>
                <ul>
                    <li><a href="#encoder">2.1 인코더</a></li>
                    <li><a href="#decoder">2.2 디코더</a></li>
                    <li><a href="#components">2.3 주요 구성 요소</a></li>
                </ul>
            </li>
            <li><a href="#attention">3. 어텐션 메커니즘</a>
                <ul>
                    <li><a href="#self-attention">3.1 셀프 어텐션</a></li>
                    <li><a href="#multi-head">3.2 멀티헤드 어텐션</a></li>
                    <li><a href="#attention-math">3.3 어텐션 수학</a></li>
                </ul>
            </li>
            <li><a href="#training">4. 학습 과정</a>
                <ul>
                    <li><a href="#pretraining">4.1 사전 학습</a></li>
                    <li><a href="#finetuning">4.2 파인튜닝</a></li>
                    <li><a href="#optimization">4.3 최적화 기법</a></li>
                </ul>
            </li>
            <li><a href="#applications">5. 응용 분야</a>
                <ul>
                    <li><a href="#nlp">5.1 자연어 처리</a></li>
                    <li><a href="#cv">5.2 컴퓨터 비전</a></li>
                    <li><a href="#other-domains">5.3 기타 도메인</a></li>
                </ul>
            </li>
            <li><a href="#advanced">6. 고급 주제</a>
                <ul>
                    <li><a href="#variants">6.1 Transformer 변형</a></li>
                    <li><a href="#scaling">6.2 모델 스케일링</a></li>
                    <li><a href="#efficiency">6.3 효율성 개선</a></li>
                </ul>
            </li>
        </ul>
    </nav>
    <main id="content">
        <!-- 각 섹션에 대한 내용 추가 -->
        <section id="intro">
            <h2>1. 소개</h2>
            <section id="background">
                <h3>1.1 배경</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="importance">
                <h3>1.2 중요성</h3>
                <div class="content-placeholder"></div>
            </section>
        </section>
        
        <section id="architecture">
            <h2>2. Transformer 아키텍처</h2>
            <section id="encoder">
                <h3>2.1 인코더</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="decoder">
                <h3>2.2 디코더</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="components">
                <h3>2.3 주요 구성 요소</h3>
                <div class="content-placeholder"></div>
            </section>
        </section>

        <section id="attention">
            <h2>3. 어텐션 메커니즘</h2>
            <section id="self-attention">
                <h3>3.1 셀프 어텐션</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="multi-head">
                <h3>3.2 멀티헤드 어텐션</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="attention-math">
                <h3>3.3 어텐션 수학</h3>
                <div class="content-placeholder"></div>
            </section>
        </section>

        <section id="training">
            <h2>4. 학습 과정</h2>
            <section id="pretraining">
                <h3>4.1 사전 학습</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="finetuning">
                <h3>4.2 파인튜닝</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="optimization">
                <h3>4.3 최적화 기법</h3>
                <div class="content-placeholder"></div>
            </section>
        </section>

        <section id="applications">
            <h2>5. 응용 분야</h2>
            <section id="nlp">
                <h3>5.1 자연어 처리</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="cv">
                <h3>5.2 컴퓨터 비전</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="other-domains">
                <h3>5.3 기타 도메인</h3>
                <div class="content-placeholder"></div>
            </section>
        </section>

        <section id="advanced">
            <h2>6. 고급 주제</h2>
            <section id="variants">
                <h3>6.1 Transformer 변형</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="scaling">
                <h3>6.2 모델 스케일링</h3>
                <div class="content-placeholder"></div>
            </section>
            <section id="efficiency">
                <h3>6.3 효율성 개선</h3>
                <div class="content-placeholder"></div>
            </section>
        </section>
    </main>
    <footer>
        <p>&copy; 2024 Transformer 모델 교육</p>
    </footer>
    <script src="script.js"></script>
</body>
</html>